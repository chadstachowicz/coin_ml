{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Grade Classifier - Vision Transformer (ViT)\n",
    "\n",
    "Train a Vision Transformer model to classify coin grades using **both obverse and reverse** images at full **1000x1000 resolution**.\n",
    "\n",
    "## Key Features:\n",
    "- \ud83e\ude99 **Dual-Image Input**: Uses both sides of each coin\n",
    "- \ud83d\udd0d **Full Resolution**: 1000x1000 pixels (preserves fine details)\n",
    "- \ud83e\udd16 **Vision Transformer**: State-of-the-art architecture\n",
    "- \ud83d\udd04 **Feature Fusion**: Combines information from both sides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Image size: 1000x1000\n",
      "Batch size: 4\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = 'images'\n",
    "OUTPUT_DIR = 'models'\n",
    "LOG_DIR = 'runs/vit_dual_' + datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = 1000\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True if torch.backends.mps.is_available() else False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DualCoinDataset(Dataset):\n    def __init__(self, data_dir, split='train', transform=None):\n        self.data_dir = Path(data_dir)\n        self.transform = transform\n        self.samples = []\n        self.class_to_idx = {}\n        self.idx_to_class = {}\n        \n        grade_folders = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])\n        \n        for idx, grade_folder in enumerate(grade_folders):\n            grade_name = grade_folder.name\n            self.class_to_idx[grade_name] = idx\n            self.idx_to_class[idx] = grade_name\n            \n            obverse_dir = grade_folder / 'obverse'\n            reverse_dir = grade_folder / 'reverse'\n            \n            if not obverse_dir.exists() or not reverse_dir.exists():\n                print(f\"Warning: Missing obverse or reverse folder for {grade_name}\")\n                continue\n            \n            # Get all obverse images (both .jpg and .png)\n            obverse_images = sorted(list(obverse_dir.glob('*.jpg')) + list(obverse_dir.glob('*.png')))\n            \n            # Build reverse image lookup by cert number\n            reverse_images = list(reverse_dir.glob('*.jpg')) + list(reverse_dir.glob('*.png'))\n            reverse_lookup = {}\n            for rev_img in reverse_images:\n                # Extract cert number from filename\n                # Format: grade-denom-CERTNO-reverse-idx.ext\n                match = re.search(r'-(\\d+)-', rev_img.name)\n                if match:\n                    cert_no = match.group(1)\n                    reverse_lookup[cert_no] = rev_img\n            \n            # Match obverse with reverse by cert number\n            matched = 0\n            for obverse_img in obverse_images:\n                # Extract cert number from obverse filename\n                match = re.search(r'-(\\d+)-', obverse_img.name)\n                if match:\n                    cert_no = match.group(1)\n                    if cert_no in reverse_lookup:\n                        self.samples.append({\n                            'obverse': obverse_img,\n                            'reverse': reverse_lookup[cert_no],\n                            'label': idx,\n                            'grade': grade_name\n                        })\n                        matched += 1\n            \n            if matched > 0:\n                print(f\"  {grade_name}: matched {matched} pairs\")\n        \n        if len(self.samples) == 0:\n            print(\"ERROR: No image pairs found!\")\n            print(\"Make sure your images/ folder has structure:\")\n            print(\"  images/<grade>/obverse/*.jpg\")\n            print(\"  images/<grade>/reverse/*.jpg\")\n            return\n        \n        # Split data (70% train, 20% test, 10% val)\n        np.random.seed(42)\n        indices = np.random.permutation(len(self.samples))\n        \n        n_train = int(0.7 * len(self.samples))\n        n_test = int(0.2 * len(self.samples))\n        \n        if split == 'train':\n            indices = indices[:n_train]\n        elif split == 'test':\n            indices = indices[n_train:n_train + n_test]\n        else:\n            indices = indices[n_train + n_test:]\n        \n        self.samples = [self.samples[i] for i in indices]\n        \n        print(f\"",
    "{split.upper()}: {len(self.samples)} samples, {len(self.class_to_idx)} classes\")\n        print(f\"Classes: {list(self.class_to_idx.keys())[:5]}{'...' if len(self.class_to_idx) > 5 else ''}\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        obverse = Image.open(sample['obverse']).convert('RGB')\n        reverse = Image.open(sample['reverse']).convert('RGB')\n        \n        if self.transform:\n            obverse = self.transform(obverse)\n            reverse = self.transform(reverse)\n        \n        return obverse, reverse, sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualCoinDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        \n",
    "        grade_folders = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        for idx, grade_folder in enumerate(grade_folders):\n",
    "            grade_name = grade_folder.name\n",
    "            self.class_to_idx[grade_name] = idx\n",
    "            self.idx_to_class[idx] = grade_name\n",
    "            \n",
    "            obverse_dir = grade_folder / 'obverse'\n",
    "            reverse_dir = grade_folder / 'reverse'\n",
    "            \n",
    "            if not obverse_dir.exists() or not reverse_dir.exists():\n",
    "                continue\n",
    "            \n",
    "            obverse_images = sorted([f for f in obverse_dir.glob('*.jpg') if f.is_file()])\n",
    "            \n",
    "            for obverse_img in obverse_images:\n",
    "                reverse_img = reverse_dir / obverse_img.name\n",
    "                if reverse_img.exists():\n",
    "                    self.samples.append({\n",
    "                        'obverse': obverse_img,\n",
    "                        'reverse': reverse_img,\n",
    "                        'label': idx,\n",
    "                        'grade': grade_name\n",
    "                    })\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        indices = np.random.permutation(len(self.samples))\n",
    "        \n",
    "        n_train = int(0.7 * len(self.samples))\n",
    "        n_test = int(0.2 * len(self.samples))\n",
    "        \n",
    "        if split == 'train':\n",
    "            indices = indices[:n_train]\n",
    "        elif split == 'test':\n",
    "            indices = indices[n_train:n_train + n_test]\n",
    "        else:\n",
    "            indices = indices[n_train + n_test:]\n",
    "        \n",
    "        self.samples = [self.samples[i] for i in indices]\n",
    "        \n",
    "        print(f\"{split.upper()}: {len(self.samples)} samples, {len(self.class_to_idx)} classes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        obverse = Image.open(sample['obverse']).convert('RGB')\n",
    "        reverse = Image.open(sample['reverse']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            obverse = self.transform(obverse)\n",
    "            reverse = self.transform(reverse)\n",
    "        \n",
    "        return obverse, reverse, sample['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Transforms configured\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"\u2713 Transforms configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0 samples, 32 classes\n",
      "TEST: 0 samples, 32 classes\n",
      "VAL: 0 samples, 32 classes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DualCoinDataset(DATA_DIR, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mval_transform)\n\u001b[1;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m DualCoinDataset(DATA_DIR, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mval_transform)\n\u001b[0;32m----> 5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m                           num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS, pin_memory\u001b[38;5;241m=\u001b[39mPIN_MEMORY)\n\u001b[1;32m      7\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                          num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS, pin_memory\u001b[38;5;241m=\u001b[39mPIN_MEMORY)\n\u001b[1;32m      9\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                         num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS, pin_memory\u001b[38;5;241m=\u001b[39mPIN_MEMORY)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:383\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 383\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/sampler.py:165\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_dataset = DualCoinDataset(DATA_DIR, split='train', transform=train_transform)\n",
    "test_dataset = DualCoinDataset(DATA_DIR, split='test', transform=val_transform)\n",
    "val_dataset = DualCoinDataset(DATA_DIR, split='val', transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(f\"Train: {len(train_loader)} batches\")\n",
    "print(f\"Test: {len(test_loader)} batches\")\n",
    "print(f\"Val: {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dual Vision Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /Users/chadstachowicz/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 330M/330M [00:08<00:00, 42.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 32\n",
      "Parameters: 173,713,952\n"
     ]
    }
   ],
   "source": [
    "class DualViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, image_size=1000, pretrained=True):\n",
    "        super().__init__()\n",
    "        from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "        \n",
    "        if pretrained:\n",
    "            weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "            obverse_vit = vit_b_16(weights=weights)\n",
    "            reverse_vit = vit_b_16(weights=weights)\n",
    "        else:\n",
    "            obverse_vit = vit_b_16(weights=None)\n",
    "            reverse_vit = vit_b_16(weights=None)\n",
    "        \n",
    "        self.obverse_encoder = nn.Sequential(obverse_vit.conv_proj, obverse_vit.encoder)\n",
    "        self.reverse_encoder = nn.Sequential(reverse_vit.conv_proj, reverse_vit.encoder)\n",
    "        self.feature_dim = 768\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim * 2, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, obverse, reverse):\n",
    "        obverse_feat = self.obverse_encoder(obverse)[:, 0]\n",
    "        reverse_feat = self.reverse_encoder(reverse)[:, 0]\n",
    "        combined = torch.cat([obverse_feat, reverse_feat], dim=1)\n",
    "        fused = self.fusion(combined)\n",
    "        output = self.classifier(fused)\n",
    "        return output\n",
    "\n",
    "num_classes = len(train_dataset.class_to_idx)\n",
    "model = DualViTClassifier(num_classes=num_classes, pretrained=True).to(DEVICE)\n",
    "\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: AdamW (LR=0.0001)\n",
      "Scheduler: CosineAnnealingLR\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "print(f\"Optimizer: AdamW (LR={LEARNING_RATE})\")\n",
    "print(f\"Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Train]')\n",
    "    for obverse, reverse, labels in pbar:\n",
    "        obverse, reverse, labels = obverse.to(device), reverse.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(obverse, reverse)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * obverse.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device, split='Val'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f'{split}')\n",
    "        for obverse, reverse, labels in pbar:\n",
    "            obverse, reverse, labels = obverse.to(device), reverse.to(device), labels.to(device)\n",
    "            outputs = model(obverse, reverse)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * obverse.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "print(\"\u2713 Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_path = os.path.join(OUTPUT_DIR, 'coin_vit_dual_best.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "    \n",
    "    print(f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_to_idx': train_dataset.class_to_idx,\n",
    "            'idx_to_class': train_dataset.idx_to_class\n",
    "        }, best_model_path)\n",
    "        print(f\"\u2713 Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Val', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train', marker='o')\n",
    "ax2.plot(history['val_acc'], label='Val', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history_vit.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, DEVICE, split='Test')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, 'history_vit.json'), 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "config = {\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'num_classes': num_classes,\n",
    "    'classes': list(train_dataset.class_to_idx.keys()),\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'test_acc': test_acc\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'config_vit.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2713 Results saved!\")\n",
    "print(f\"  Model: {best_model_path}\")\n",
    "print(f\"  History: {OUTPUT_DIR}/history_vit.json\")\n",
    "print(f\"  Config: {OUTPUT_DIR}/config_vit.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}