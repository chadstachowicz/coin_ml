{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Coin Grade Classifier - Dual-Image ResNet Fine-Tuning\n",
        "\n",
        "This notebook fine-tunes a **pretrained ResNet-50** model to classify coin grades using **both obverse and reverse** images at full **1000x1000 resolution**.\n",
        "\n",
        "## Key Features:\n",
        "- ü™ô **Dual-Image Input**: Uses both sides of each coin\n",
        "- üîç **Full Resolution**: 1000x1000 pixels (preserves fine details)\n",
        "- üéØ **Transfer Learning**: ResNet-50 pretrained on ImageNet\n",
        "- üîÑ **Feature Fusion**: Combines information from both sides\n",
        "- üßä **Progressive Unfreezing**: Frozen ‚Üí Fine-tuned backbone\n",
        "\n",
        "## Architecture:\n",
        "```\n",
        "Obverse (1000x1000)     Reverse (1000x1000)\n",
        "        ‚Üì                       ‚Üì\n",
        "   ResNet-50               ResNet-50\n",
        "  (Pretrained)            (Pretrained)\n",
        "    (2048 dim)              (2048 dim)\n",
        "        ‚Üì                       ‚Üì\n",
        "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Concatenate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                 ‚Üì\n",
        "           Fusion Layer\n",
        "             (2048)\n",
        "                 ‚Üì\n",
        "       Classification Head\n",
        "                 ‚Üì\n",
        "            Coin Grade\n",
        "```\n",
        "\n",
        "## Training Strategy:\n",
        "1. **Phase 1** (Epochs 1-15): Freeze ResNet backbone, train only classifier\n",
        "2. **Phase 2** (Epochs 16-50): Unfreeze all layers, fine-tune end-to-end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.6.0\n",
            "CUDA available: False\n",
            "MPS (Apple Silicon) available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    print(\"MPS (Apple Silicon) available: True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Key settings:\n",
        "- **IMAGE_SIZE**: 1000 (full resolution)\n",
        "- **FREEZE_BACKBONE**: True (freeze ResNet initially)\n",
        "- **UNFREEZE_EPOCH**: 15 (when to start fine-tuning backbone)\n",
        "- **DATA_DIR**: Choose 'Proof' or 'Circulation' subfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MPS (Apple Silicon GPU)\n",
            "\n",
            "Device: mps\n",
            "Image size: 256x256\n",
            "Batch size: 4\n",
            "Epochs: 50\n",
            "Data directory: davidlawrence_dataset/Circulation\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "DATA_DIR = 'davidlawrence_dataset/Circulation'  # or 'davidlawrence_dataset/Circulation'\n",
        "OUTPUT_DIR = 'models'\n",
        "LOG_DIR = 'runs/resnet_dual_' + datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Model hyperparameters\n",
        "IMAGE_SIZE = 256  # Full resolution\n",
        "BATCH_SIZE = 4     # Small batch due to large images\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 1e-4\n",
        "FREEZE_BACKBONE = True  # Freeze early ResNet layers initially\n",
        "UNFREEZE_EPOCH = 15     # Unfreeze all layers after this epoch\n",
        "\n",
        "# Device selection\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "    print(\"Using CUDA (NVIDIA GPU)\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device('mps')\n",
        "    print(\"Using MPS (Apple Silicon GPU)\")\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\nDevice: {DEVICE}\")\n",
        "print(f\"Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Class - Dual Image Loader\n",
        "\n",
        "Loads both obverse and reverse images for each coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DualCoinDataset(Dataset):\n",
        "    \"\"\"Dataset that loads both obverse and reverse images for each coin.\"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir, split='train', transform=None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.class_to_idx = {}\n",
        "        self.idx_to_class = {}\n",
        "        \n",
        "        # Scan for grade folders\n",
        "        grade_folders = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])\n",
        "        \n",
        "        for idx, grade_folder in enumerate(grade_folders):\n",
        "            grade_name = grade_folder.name\n",
        "            self.class_to_idx[grade_name] = idx\n",
        "            self.idx_to_class[idx] = grade_name\n",
        "            \n",
        "            obverse_dir = grade_folder / 'obverse'\n",
        "            reverse_dir = grade_folder / 'reverse'\n",
        "            \n",
        "            if not obverse_dir.exists() or not reverse_dir.exists():\n",
        "                print(f\"Warning: Missing obverse or reverse folder for {grade_name}\")\n",
        "                continue\n",
        "            \n",
        "            obverse_images = sorted([f for f in obverse_dir.glob('*.jpg') if f.is_file()])\n",
        "            \n",
        "            for obverse_img in obverse_images:\n",
        "                reverse_img = reverse_dir / obverse_img.name\n",
        "                \n",
        "                if reverse_img.exists():\n",
        "                    self.samples.append({\n",
        "                        'obverse': obverse_img,\n",
        "                        'reverse': reverse_img,\n",
        "                        'label': idx,\n",
        "                        'grade': grade_name\n",
        "                    })\n",
        "        \n",
        "        # Split data (70% train, 20% test, 10% val)\n",
        "        np.random.seed(42)\n",
        "        indices = np.random.permutation(len(self.samples))\n",
        "        \n",
        "        n_train = int(0.7 * len(self.samples))\n",
        "        n_test = int(0.2 * len(self.samples))\n",
        "        \n",
        "        if split == 'train':\n",
        "            indices = indices[:n_train]\n",
        "        elif split == 'test':\n",
        "            indices = indices[n_train:n_train + n_test]\n",
        "        else:  # val\n",
        "            indices = indices[n_train + n_test:]\n",
        "        \n",
        "        self.samples = [self.samples[i] for i in indices]\n",
        "        \n",
        "        print(f\"{split.upper()} Dataset:\")\n",
        "        print(f\"  Total samples: {len(self.samples)}\")\n",
        "        print(f\"  Classes: {len(self.class_to_idx)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        obverse = Image.open(sample['obverse']).convert('RGB')\n",
        "        reverse = Image.open(sample['reverse']).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            obverse = self.transform(obverse)\n",
        "            reverse = self.transform(reverse)\n",
        "        \n",
        "        return obverse, reverse, sample['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Transforms\n",
        "\n",
        "ImageNet normalization for pretrained ResNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Transforms configured\n"
          ]
        }
      ],
      "source": [
        "# Training transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Validation/test transforms\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"‚úì Transforms configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN Dataset:\n",
            "  Total samples: 2585\n",
            "  Classes: 24\n",
            "TEST Dataset:\n",
            "  Total samples: 738\n",
            "  Classes: 24\n",
            "VAL Dataset:\n",
            "  Total samples: 371\n",
            "  Classes: 24\n",
            "\n",
            "Dataloaders created:\n",
            "  Train batches: 647\n",
            "  Test batches: 185\n",
            "  Val batches: 93\n"
          ]
        }
      ],
      "source": [
        "# Create datasets\n",
        "train_dataset = DualCoinDataset(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = DualCoinDataset(DATA_DIR, split='test', transform=val_transform)\n",
        "val_dataset = DualCoinDataset(DATA_DIR, split='val', transform=val_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
        "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "print(f\"\\nDataloaders created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n",
        "print(f\"  Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dual ResNet Model\n",
        "\n",
        "Two ResNet-50 encoders with feature fusion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Backbone layers frozen\n",
            "\n",
            "Model created:\n",
            "  Number of classes: 24\n",
            "  Total params: 58,049,176\n",
            "  Trainable params: 11,033,112\n"
          ]
        }
      ],
      "source": [
        "class DualResNetClassifier(nn.Module):\n",
        "    \"\"\"ResNet-50 for dual-image classification.\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes, freeze_backbone=True):\n",
        "        super(DualResNetClassifier, self).__init__()\n",
        "        \n",
        "        # Load pretrained ResNet-50\n",
        "        weights = ResNet50_Weights.IMAGENET1K_V2\n",
        "        obverse_resnet = resnet50(weights=weights)\n",
        "        reverse_resnet = resnet50(weights=weights)\n",
        "        \n",
        "        # Remove final FC layer (keep 2048-dim features)\n",
        "        self.obverse_encoder = nn.Sequential(*list(obverse_resnet.children())[:-1])\n",
        "        self.reverse_encoder = nn.Sequential(*list(reverse_resnet.children())[:-1])\n",
        "        \n",
        "        # Freeze backbone if requested\n",
        "        if freeze_backbone:\n",
        "            for param in self.obverse_encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.reverse_encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"‚úì Backbone layers frozen\")\n",
        "        \n",
        "        self.feature_dim = 2048\n",
        "        \n",
        "        # Fusion layer\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim * 2, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        \n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    \n",
        "    def unfreeze_backbone(self):\n",
        "        \"\"\"Unfreeze all backbone layers.\"\"\"\n",
        "        for param in self.obverse_encoder.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in self.reverse_encoder.parameters():\n",
        "            param.requires_grad = True\n",
        "        print(\"‚úì Backbone layers unfrozen\")\n",
        "    \n",
        "    def forward(self, obverse, reverse):\n",
        "        obverse_feat = self.obverse_encoder(obverse).view(obverse.size(0), -1)\n",
        "        reverse_feat = self.reverse_encoder(reverse).view(reverse.size(0), -1)\n",
        "        combined = torch.cat([obverse_feat, reverse_feat], dim=1)\n",
        "        fused = self.fusion(combined)\n",
        "        output = self.classifier(fused)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Create model\n",
        "num_classes = len(train_dataset.class_to_idx)\n",
        "model = DualResNetClassifier(num_classes=num_classes, freeze_backbone=FREEZE_BACKBONE)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel created:\")\n",
        "print(f\"  Number of classes: {num_classes}\")\n",
        "print(f\"  Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"  Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training setup complete\n",
            "  Optimizer: AdamW\n",
            "  Learning rate: 0.0001\n",
            "  TensorBoard logs: runs/resnet_dual_20251130_233517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        ")\n",
        "\n",
        "# TensorBoard writer\n",
        "writer = SummaryWriter(LOG_DIR)\n",
        "\n",
        "print(\"Training setup complete\")\n",
        "print(f\"  Optimizer: AdamW\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  TensorBoard logs: {LOG_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training and Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Training functions defined\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Train]')\n",
        "    \n",
        "    for obverse, reverse, labels in pbar:\n",
        "        obverse, reverse, labels = obverse.to(device), reverse.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(obverse, reverse)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item() * obverse.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
        "    \n",
        "    return running_loss / total, 100 * correct / total\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion, device, split='Val'):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(loader, desc=f'{split}')\n",
        "        for obverse, reverse, labels in pbar:\n",
        "            obverse, reverse, labels = obverse.to(device), reverse.to(device), labels.to(device)\n",
        "            outputs = model(obverse, reverse)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item() * obverse.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
        "    \n",
        "    return running_loss / total, 100 * correct / total\n",
        "\n",
        "print(\"‚úì Training functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Main Training Loop\n",
        "\n",
        "**Run this cell to start training!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "Epoch 1/50\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 646/647 [02:18<00:00,  4.65it/s, loss=2.2849, acc=23.72%]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 2048])",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train and validate\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch)\n\u001b[1;32m     22\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, DEVICE)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Update LR\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m obverse, reverse, labels \u001b[38;5;241m=\u001b[39m obverse\u001b[38;5;241m.\u001b[39mto(device), reverse\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(obverse, reverse)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[15], line 59\u001b[0m, in \u001b[0;36mDualResNetClassifier.forward\u001b[0;34m(self, obverse, reverse)\u001b[0m\n\u001b[1;32m     57\u001b[0m reverse_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreverse_encoder(reverse)\u001b[38;5;241m.\u001b[39mview(reverse\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([obverse_feat, reverse_feat], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m fused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfusion(combined)\n\u001b[1;32m     60\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(fused)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    202\u001b[0m     bn_training,\n\u001b[1;32m    203\u001b[0m     exponential_average_factor,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    205\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:2820\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2808\u001b[0m         batch_norm,\n\u001b[1;32m   2809\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2817\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2818\u001b[0m     )\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2823\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2824\u001b[0m     weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2831\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[1;32m   2832\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:2786\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2784\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2787\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2788\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 2048])"
          ]
        }
      ],
      "source": [
        "# Training history\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "best_val_acc = 0.0\n",
        "best_model_path = os.path.join(OUTPUT_DIR, 'coin_resnet_dual_best.pth')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Unfreeze backbone after specified epoch\n",
        "    if FREEZE_BACKBONE and epoch == UNFREEZE_EPOCH:\n",
        "        print(f\"\\nüîì Unfreezing backbone at epoch {epoch+1}\")\n",
        "        model.unfreeze_backbone()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE/10, weight_decay=0.01)\n",
        "    \n",
        "    # Train and validate\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
        "    \n",
        "    # Update LR\n",
        "    scheduler.step(val_acc)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    \n",
        "    # Log to TensorBoard\n",
        "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
        "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
        "    print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
        "    print(f\"  LR: {current_lr:.6f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'class_to_idx': train_dataset.class_to_idx\n",
        "        }, best_model_path)\n",
        "        print(f\"  ‚úì New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
        "\n",
        "print(f\"\\nBest validation accuracy: {best_val_acc:.2f}%\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "if FREEZE_BACKBONE:\n",
        "    ax1.axvline(x=UNFREEZE_EPOCH, color='red', linestyle='--', alpha=0.5, label='Unfreeze')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.plot(history['train_acc'], label='Train Acc', marker='o')\n",
        "ax2.plot(history['val_acc'], label='Val Acc', marker='s')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "if FREEZE_BACKBONE:\n",
        "    ax2.axvline(x=UNFREEZE_EPOCH, color='red', linestyle='--', alpha=0.5, label='Unfreeze')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history_resnet.png'), dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load(best_model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = validate(model, test_loader, criterion, DEVICE, split='Test')\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FINAL TEST RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. View TensorBoard\n",
        "\n",
        "```bash\n",
        "tensorboard --logdir=runs\n",
        "```\n",
        "\n",
        "Then open http://localhost:6006"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save history and config\n",
        "with open(os.path.join(OUTPUT_DIR, 'history_resnet.json'), 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "config = {\n",
        "    'architecture': 'DualResNetClassifier (ResNet-50)',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'best_val_acc': best_val_acc,\n",
        "    'test_acc': test_acc\n",
        "}\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, 'config_resnet.json'), 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"‚úì All results saved!\")\n",
        "print(f\"  Best Val Acc: {best_val_acc:.2f}%\")\n",
        "print(f\"  Test Acc: {test_acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
